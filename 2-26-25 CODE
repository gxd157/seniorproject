import cv2
import numpy as np
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort

# Load YOLOv8 model
model = YOLO("yolov8n.pt")

# Initialize DeepSORT Tracker
tracker = DeepSort(max_age=30)

# Video capture
cap = cv2.VideoCapture(0)

# Get frame dimensions & middle separation line
frame_height = int(cap.get(4))
middle_y = frame_height // 2  # Horizontal middle line

# Tracking movement
tracking_data = {}  # {ID: [initial_y, last_y, frames_since_update]}
enter_count, exit_count = 0, 0

CROSSING_THRESHOLD = 50  # Min distance beyond middle line to confirm entry/exit
MAX_LOST_FRAMES = 30  # Remove IDs if not updated for this many frames

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    results = model(frame)  # Run YOLO detection
    detections = []

    # Process YOLO detections
    for result in results:
        boxes = result.boxes.xyxy.cpu().numpy()  # Convert tensor to NumPy
        confidences = result.boxes.conf.cpu().numpy()
        class_ids = result.boxes.cls.cpu().numpy().astype(int)

        for box, conf, cls in zip(boxes, confidences, class_ids):
            x1, y1, x2, y2 = map(int, box[:4])
            confidence = float(conf)

            # Only track people (class ID 0)
            if confidence > 0.7 and cls == 0:
                detections.append(([x1, y1, x2, y2], confidence, "person"))  # âœ… Corrected format

    # Run DeepSORT tracker
    tracks = tracker.update_tracks(detections, frame=frame)

    active_ids = set()  # Track IDs seen in this frame

    for track in tracks:
        if not track.is_confirmed():
            continue

        track_id = track.track_id
        active_ids.add(track_id)  # Store active track ID
        x1, y1, x2, y2 = map(int, track.to_tlbr())  # Get exact bounding box from DeepSORT

        centroid_x = (x1 + x2) // 2  # Center X coordinate
        centroid_y = (y1 + y2) // 2  # Center Y coordinate

        # Draw bounding box for tracked persons
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)  
        cv2.putText(frame, f"ID {track_id}", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

        # Store initial position for new IDs
        if track_id not in tracking_data:
            tracking_data[track_id] = [centroid_y, centroid_y, 0]  # (start_y, last_y, frames_since_update)
        else:
            tracking_data[track_id][1] = centroid_y  # Update last Y position
            tracking_data[track_id][2] = 0  # Reset frame counter since ID is still active

    # Analyze movement only when a person fully crosses the middle line
    for track_id, (start_y, last_y, frames_since_update) in list(tracking_data.items()):
        if abs(last_y - start_y) < 50:  # Ignore small shifts
            continue

        if start_y < middle_y and last_y > middle_y + CROSSING_THRESHOLD:  # Moving Down -> Exiting
            exit_count += 1
            del tracking_data[track_id]
        elif start_y > middle_y and last_y < middle_y - CROSSING_THRESHOLD:  # Moving Up -> Entering
            enter_count += 1
            del tracking_data[track_id]
        else:
            tracking_data[track_id][2] += 1  # Increase frames since last update

    # Remove stale IDs not updated for MAX_LOST_FRAMES
    for track_id in list(tracking_data.keys()):
        if tracking_data[track_id][2] > MAX_LOST_FRAMES:
            del tracking_data[track_id]

    # Draw middle horizontal line
    cv2.line(frame, (0, middle_y), (frame.shape[1], middle_y), (255, 0, 0), 2)  # Horizontal line

    # Resize frame for larger display
    frame = cv2.resize(frame, (1280, 720))  # Resize display to 1280x720

    # Display count statistics (smaller size)
    cv2.putText(frame, f"Entered: {enter_count}", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)  
    cv2.putText(frame, f"Exited: {exit_count}", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)  

    cv2.imshow("Occupancy Counter", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
